{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e559c859-c3bb-4eac-83e0-f7ffe5da9d84",
   "metadata": {},
   "source": [
    "## Importing all the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "781375a7-c384-4c8f-8ca7-927704e21e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a49b8-66b7-4d23-bb3f-2ad6de4394ba",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec8e2fb-6b16-41d1-bc9f-4b6d7db1457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b759f4c1-3b2a-4d77-8e8e-1aa5f35f205e",
   "metadata": {},
   "source": [
    "## Preprocess dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f06a54c7-f313-496f-9778-30c90e972008",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['SignupDate'] = pd.to_datetime(customers['SignupDate'])\n",
    "transactions['TransactionDate'] = pd.to_datetime(transactions['TransactionDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04cf9e-b130-4f7b-aee7-a425317dbe3b",
   "metadata": {},
   "source": [
    "## Determine max transaction date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b19efebf-10a2-493e-8e74-287b489a49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_transaction_date = transactions['TransactionDate'].max()\n",
    "\n",
    "# Calculate Tenure (days from signup to last transaction date)\n",
    "customers['Tenure'] = (max_transaction_date - customers['SignupDate']).dt.days\n",
    "\n",
    "# One-hot encode Region\n",
    "customers = pd.get_dummies(customers, columns=['Region'], prefix='Region')\n",
    "\n",
    "# Merge transactions with product categories\n",
    "transactions = pd.merge(transactions, products[['ProductID', 'Category']], on='ProductID', how='left')\n",
    "\n",
    "# Prepare list of all customer IDs\n",
    "all_customers = customers['CustomerID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e40b79-cded-4195-b367-ec53221f4e17",
   "metadata": {},
   "source": [
    "##  RFM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4afc6466-eb15-467a-af90-ba41cec86f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rfm = transactions.groupby('CustomerID').agg(\n",
    "    Frequency=('TransactionID', 'count'),\n",
    "    Monetary=('TotalValue', 'sum'),\n",
    "    Last_Transaction=('TransactionDate', 'max')\n",
    ").reset_index()\n",
    "rfm['Recency'] = (max_transaction_date - rfm['Last_Transaction']).dt.days\n",
    "rfm = rfm[['CustomerID', 'Frequency', 'Monetary', 'Recency']]\n",
    "\n",
    "# Merge RFM with all customers (including those with no transactions)\n",
    "rfm_all = pd.DataFrame({'CustomerID': all_customers})\n",
    "rfm_all = rfm_all.merge(rfm, on='CustomerID', how='left').fillna({'Frequency': 0, 'Monetary': 0, 'Recency': 9999})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09edcc07-7713-4ba3-9bb6-53db78f4f48f",
   "metadata": {},
   "source": [
    "## Saving our Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28039798-4f26-4159-81db-2923bd1d0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Category Preferences\n",
    "category_counts = transactions.groupby(['CustomerID', 'Category']).size().unstack(fill_value=0).reset_index()\n",
    "\n",
    "# Merging Categories with all customers\n",
    "categories_all = pd.DataFrame({'CustomerID': all_customers})\n",
    "categories_all = categories_all.merge(category_counts, on='CustomerID', how='left').fillna(0)\n",
    "\n",
    "# Averaging the Price and Quantity\n",
    "avg_features = transactions.groupby('CustomerID').agg(\n",
    "    Avg_Price=('Price', 'mean'),\n",
    "    Avg_Quantity=('Quantity', 'mean')\n",
    ").reset_index().fillna(0)\n",
    "\n",
    "# Merging all features\n",
    "final_features = customers.merge(rfm_all, on='CustomerID') \\\n",
    "                          .merge(categories_all, on='CustomerID') \\\n",
    "                          .merge(avg_features, on='CustomerID', how='left') \\\n",
    "                          .fillna(0)\n",
    "\n",
    "# Droping non-feature columns\n",
    "final_features.drop(['CustomerName', 'SignupDate'], axis=1, inplace=True)\n",
    "\n",
    "# Scaling numerical features\n",
    "numerical_cols = ['Tenure', 'Frequency', 'Monetary', 'Recency'] + \\\n",
    "                 [col for col in final_features.columns if col.startswith('Category_')] + \\\n",
    "                 ['Avg_Price', 'Avg_Quantity']\n",
    "scaler = StandardScaler()\n",
    "final_features[numerical_cols] = scaler.fit_transform(final_features[numerical_cols])\n",
    "\n",
    "# Computing similarity matrix\n",
    "customer_ids = final_features['CustomerID'].tolist()\n",
    "features = final_features.drop('CustomerID', axis=1)\n",
    "similarity_matrix = cosine_similarity(features)\n",
    "\n",
    "lookalike_map = {}\n",
    "target_customers = customer_ids[:20]  # First 20 customers\n",
    "\n",
    "for cust_id in target_customers:\n",
    "    idx = customer_ids.index(cust_id)\n",
    "    similarities = similarity_matrix[idx]\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    top_indices = [i for i in sorted_indices if customer_ids[i] != cust_id][:3]\n",
    "    top_similar = [[customer_ids[i], float(similarities[i])] for i in top_indices]\n",
    "    lookalike_map[cust_id] = top_similar\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "lookalike_df = pd.DataFrame({\n",
    "    'CustomerID': lookalike_map.keys(),\n",
    "    'Lookalikes': lookalike_map.values()\n",
    "})\n",
    "\n",
    "# Formating  the \"Lookalikes\" column as a string of lists\n",
    "lookalike_df['Lookalikes'] = lookalike_df['Lookalikes'].apply(\n",
    "    lambda x: str([[cust, round(score, 4)] for cust, score in x])\n",
    ")\n",
    "\n",
    "lookalike_df.to_csv('Lookalikee.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
